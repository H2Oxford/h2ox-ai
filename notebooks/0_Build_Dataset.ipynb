{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a72e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import xarray as xr\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "from h2ox.ai.dataset.dataset_factory import DatasetFactory\n",
    "from h2ox.ai.dataset.dataset import FcastDataset\n",
    "from h2ox.ai.dataset.utils import group_consecutive_nans\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f35b8dc",
   "metadata": {},
   "source": [
    "# test DatasetFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4c3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = yaml.load(open('./../conf.yaml','r'), Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd74b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_factory = DatasetFactory(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test pytorch dataset build\n",
    "ptdf = dataset_factory.build_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58cf92a",
   "metadata": {},
   "source": [
    "# Walkthrough building dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data build\n",
    "data = dataset_factory._build_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88481595",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_horizon=14\n",
    "future_horizon=76\n",
    "historical_seq_len=60\n",
    "target_var= [\"targets_WATER_VOLUME\"]\n",
    "historic_variables= [\"historic_t2m\",\"historic_tp\",\"targets_WATER_VOLUME\",\"doy_cos\"] \n",
    "forecast_variables= [\"forecast_tp\", \"forecast_t2m\",\"doy_cos\"]\n",
    "future_variables= [\"doy_cos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb10f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_historic_data(\n",
    "    data: xr.Dataset,\n",
    ") -> xr.Dataset:\n",
    "\n",
    "    data_h = xr.concat(\n",
    "        [\n",
    "            data[historic_variables].sel({'steps':np.timedelta64(0)}).shift({'date':ii}) \n",
    "            for ii in range(historical_seq_len)\n",
    "        ],\n",
    "        pd.TimedeltaIndex([timedelta(days=historical_seq_len - ii) for ii in range(historical_seq_len)], name=\"historic_roll\")\n",
    "    )\n",
    "\n",
    "    return data_h.to_array().transpose('date','global_sites','variable','historic_roll')\n",
    "\n",
    "\n",
    "def _get_forecast_data(\n",
    "    data: xr.Dataset,\n",
    ") -> xr.Dataset:\n",
    "\n",
    "    forecast_period = pd.TimedeltaIndex([timedelta(days=ii) for ii in range(1,forecast_horizon+1)])\n",
    "\n",
    "    return data[forecast_variables].to_array().sel({'steps':forecast_period}).transpose('date','global_sites','variable','steps')\n",
    "\n",
    "\n",
    "def _get_future_data(\n",
    "    data: xr.Dataset,\n",
    ") -> xr.Dataset:\n",
    "\n",
    "    future_period = pd.TimedeltaIndex([timedelta(days=ii) for ii in range(forecast_horizon+1,future_horizon+1)])\n",
    "\n",
    "    return data[future_variables].to_array().sel({'steps':future_period}).transpose('date','global_sites','variable','steps')\n",
    "\n",
    "\n",
    "def _get_target_data(\n",
    "    data: xr.Dataset,\n",
    ") -> xr.Dataset:\n",
    "\n",
    "    data_y = xr.concat(\n",
    "        [\n",
    "            data[target_var].sel({'steps':np.timedelta64(0)}).shift({'date':ii}) \n",
    "            for ii in range(forecast_horizon+future_horizon+1)\n",
    "        ],\n",
    "        pd.TimedeltaIndex([timedelta(days=ii) for ii in range(forecast_horizon+future_horizon+1)], name=\"target_roll\")\n",
    "    )\n",
    "\n",
    "    return data_y.to_array().transpose('date','global_sites','variable','target_roll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d69a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _onehotencode(data_portion, offset_dim):\n",
    "    ohe = pd.get_dummies(\n",
    "        data_portion.transpose('date','global_sites',offset_dim,'variable').stack({\"date-site\":('date','global_sites')})['global_sites'].to_dataframe()\n",
    "    ).to_xarray()\n",
    "\n",
    "    return xr.merge([data_portion.to_dataset(dim='variable'), ohe]).stack({\"date-site\":('date','global_sites')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c0b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "historic = _get_historic_data(data).drop('steps')\n",
    "forecast = _get_forecast_data(data)\n",
    "future = _get_future_data(data)\n",
    "target = _get_target_data(data).drop('steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2724078",
   "metadata": {},
   "outputs": [],
   "source": [
    "historic = _onehotencode(historic, 'historic_roll')\n",
    "forecast = _onehotencode(forecast, 'steps')\n",
    "future = _onehotencode(future, 'steps')\n",
    "target = _onehotencode(target, 'target_roll')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m75"
  },
  "kernelspec": {
   "display_name": "Python (h2ox-ai)",
   "language": "python",
   "name": "h2ox-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
